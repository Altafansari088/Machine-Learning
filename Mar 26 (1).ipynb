{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0909c5-954a-4af0-a6bb-b90e58acb61f",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c63651-c6b9-4b25-b9cd-a6b410d29fda",
   "metadata": {},
   "source": [
    "Ans.Simple linear regression involves predicting a dependent variable using a single independent variable. It assumes a linear relationship between the variables. For example, predicting house prices based on the square footage of the house.\n",
    "\n",
    "Multiple linear regression, on the other hand, involves predicting a dependent variable using multiple independent variables. It allows for more complex relationships between the variables. For example, predicting a person's salary based on their age, education level, and years of experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b2cce-0907-4597-a10a-d62defe7b537",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a5235-6c43-4b2e-a00e-c86bff44e52a",
   "metadata": {},
   "source": [
    "Ans.The assumptions of linear regression include linearity, independence, homoscedasticity, normality, and no multicollinearity. To check whether these assumptions hold in a given dataset, you can perform diagnostic tests such as plotting residuals, checking for multicollinearity using variance inflation factor (VIF), and conducting tests for normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfff06-ad86-4c58-a7ac-2368537eb15f",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb50ef-6153-49df-bc89-354337772647",
   "metadata": {},
   "source": [
    "Ans.In a linear regression model, the slope represents the change in the dependent variable for a one-unit change in the independent variable, while the intercept represents the value of the dependent variable when all independent variables are zero. For example, in a house price prediction model, the slope represents the increase in house price for every additional square footage, and the intercept represents the base price of a house with zero square footage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e1f20-e66f-4dea-9cd3-8323e7fa6931",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c7572-8526-4445-a9e5-1a634b5b3a84",
   "metadata": {},
   "source": [
    "Ans.Gradient descent is an optimization algorithm used in machine learning to minimize the error or cost function of a model. It works by iteratively adjusting the model's parameters in the direction of steepest descent of the cost function. This process continues until the algorithm converges to the minimum of the cost function, resulting in optimal parameter values for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4cc6f-f409-467b-82f8-046ecde26f93",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcf383b-3e32-488c-9b85-053c3d225815",
   "metadata": {},
   "source": [
    "Ans.Multiple linear regression is a statistical model that predicts a dependent variable using multiple independent variables. It extends the concept of simple linear regression by allowing for the consideration of multiple factors that may influence the dependent variable. The multiple linear regression model can capture more complex relationships between the variables compared to simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3c2f8-d3e2-4c8f-88b3-bd97d5234e24",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084eb6dc-5b9c-4bea-b4fc-9b1d8f31cc52",
   "metadata": {},
   "source": [
    "Ans.Multicollinearity refers to a high correlation between independent variables in a multiple linear regression model. It can cause issues in the model, such as unstable coefficient estimates and difficulty in interpreting the individual effects of the variables. To detect multicollinearity, you can calculate the variance inflation factor (VIF) for each independent variable. A high VIF indicates high multicollinearity. To address multicollinearity, you can consider removing one of the correlated variables or using dimensionality reduction techniques like principal component analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c967369-462a-4443-9733-528fe5baf78e",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bc785-be1c-4a2b-90f7-ce5a4a1704c7",
   "metadata": {},
   "source": [
    "Ans.Polynomial regression is a form of regression analysis where the relationship between the independent variable(s) and the dependent variable is modeled as an nth-degree polynomial. It allows for curved relationships between the variables, unlike linear regression, which assumes a linear relationship. Polynomial regression can capture more complex patterns in the data but may also be prone to overfitting if the degree of the polynomial is too high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5fc1c3-4040-402a-aed5-d84e4587e96c",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648489dd-b771-4d9b-a3cc-ebed1fa92260",
   "metadata": {},
   "source": [
    "Ans.Advantages of polynomial regression include its ability to capture non-linear relationships, flexibility in modeling complex patterns, and potential for improved model fit. However, polynomial regression can be more computationally expensive, prone to overfitting, and may require careful selection of the polynomial degree. Polynomial regression is preferred when there is evidence of non-linear relationships between variables or when the data exhibits curvature that cannot be adequately captured by a linear model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
