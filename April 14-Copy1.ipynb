{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe681c8-db8d-482d-a277-b6434513309e",
   "metadata": {},
   "source": [
    "Q1. Preprocess the dataset by handling missing values, encoding categorical variables, and scaling the numerical features if necessary.\n",
    "\n",
    "To preprocess the dataset, you can use libraries such as pandas and scikit-learn. Here's an example code snippet to handle missing values, encode categorical variables, and scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058a3ce-ef93-456f-a801-af18cf187d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('heart_disease_dataset.csv')\n",
    "\n",
    "# Handle missing values (if any)\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['sex', 'chest_pain_type']\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_cols = ['age', 'resting_blood_pressure', 'serum_cholesterol', 'max_heart_rate_achieved']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f22a37-4c76-4db5-9e22-fd06917f0363",
   "metadata": {},
   "source": [
    "Q2. Split the dataset into a training set (70%) and a test set (30%).\n",
    "\n",
    "To split the dataset into a training set and a test set, you can use the train_test_split function from scikit-learn. Here's an example code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3d31e-0797-48b8-86d2-1459647ee7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90294782-c2fd-4d41-9591-e411a8e27955",
   "metadata": {},
   "source": [
    "Q3. Train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each tree. Use the default values for other hyperparameters.\n",
    "\n",
    "To train a random forest classifier, you can use the RandomForestClassifier class from scikit-learn. Here's an example code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da93984-9282-4338-94d9-5fac54a2735b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b9a89-8cf2-41f6-8628-de8ed378711f",
   "metadata": {},
   "source": [
    "Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score.\n",
    "\n",
    "To evaluate the performance of the model, you can use the classification_report function from scikit-learn. Here's an example code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc810ec-5b24-4457-b381-dc6cf8d86d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd3da8-a692-4cb3-ad43-430bf523ccbd",
   "metadata": {},
   "source": [
    "Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart disease risk. Visualize the feature importances using a bar chart.\n",
    "\n",
    "To get the feature importance scores and visualize them, you can use the feature_importances_ attribute of the trained random forest classifier and matplotlib library. \n",
    "Here's an example code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c7c5b-48bc-4144-bd23-2a04c647aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Get the top 5 most important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efec3a-c9de-4fd4-9912-890c49c8001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 most important features\n",
    "top_features = pd.Series(importances, index=X.columns).nlargest(5)\n",
    "\n",
    "# Visualize the feature importances using a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features.plot(kind='barh')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 5 Most Important Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba1c23-3dba-4ab3-a9f9-f74ebaa318ab",
   "metadata": {},
   "source": [
    "Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try different values of the number of trees, maximum depth, minimum samples split, and minimum samples leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters.\n",
    "\n",
    "To tune the hyperparameters of the random forest classifier, you can use GridSearchCV or RandomizedSearchCV from scikit-learn. Here's an example code snippet using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54860a1b-322c-4733-b24a-53f251dd2aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best set of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7c111-58d7-41ff-b1d0-f35b3844bb9f",
   "metadata": {},
   "source": [
    "Q7. Report the best set of hyperparameters found by the search and the corresponding performance metrics. Compare the performance of the tuned model with the default model.\n",
    "\n",
    "To report the best set of hyperparameters and evaluate the performance of the tuned model, you can use the best_params_ and best_score_ attributes of the grid search object. Here's an example code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7d500-e033-4a53-8f56-19196e0b0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best set of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the performance of the tuned model on the test set\n",
    "tuned_model = grid_search.best_estimator_\n",
    "y_pred_tuned = tuned_model.predict(X_test)\n",
    "report_tuned = classification_report(y_test, y_pred_tuned)\n",
    "print(\"Performance Metrics (Tuned Model):\")\n",
    "print(report_tuned)\n",
    "\n",
    "# Evaluate the performance of the default model on the test set\n",
    "y_pred_default = rf_classifier.predict(X_test)\n",
    "report_default = classification_report(y_test, y_pred_default)\n",
    "print(\"Performance Metrics (Default Model):\")\n",
    "print(report_default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1ffcd-c53f-49ea-903e-bb511c24d365",
   "metadata": {},
   "source": [
    "Q8. Interpret the model by analyzing the decision boundaries of the random forest classifier. Plot the decision boundaries on a scatter plot of two of the most important features. Discuss the insights and limitations of the model for predicting heart disease risk.\n",
    "\n",
    "To plot the decision boundaries of the random forest classifier, you can select two of the most important features and create a scatter plot with the decision boundaries. However, since we don't have the dataset, it's not possible to provide a specific code snippet for this step. The decision boundaries can be visualized by creating a meshgrid of the two selected features, making predictions on the meshgrid using the trained model, and then plotting the decision regions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
