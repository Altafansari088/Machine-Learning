{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "### Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its  application.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ans.Min-Max scaling, also known as normalization, is a popular data preprocessing technique used to rescale numerical features to a specific range. It transforms the data in such a way that it is bounded within a given interval, typically between 0 and 1.\n\nThe formula to perform Min-Max scaling on a feature is as follows:\n\nscaled_value = (value - min_value) / (max_value - min_value)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ans.The Unit Vector technique, also known as vector normalization or feature scaling by normalization, is a data preprocessing method used to transform features to have a unit norm or length. Unlike Min-Max scaling, which maps the values to a specific range, the Unit Vector technique adjusts the values based on their relative magnitudes to ensure they are all on the same scale.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ans.PCA (Principal Component Analysis) is a statistical technique used for dimensionality reduction in machine learning and data analysis. It transforms a high-dimensional dataset into a lower-dimensional space while preserving the most important information or patterns present in the data. It achieves this by identifying the principal components, which are linear combinations of the original features that capture the maximum amount of variance in the data.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ans.PCA (Principal Component Analysis) can be used as a feature extraction technique in machine learning and data analysis. Feature extraction aims to transform the original features into a new set of features that are more informative or representative of the underlying patterns in the data. PCA achieves this by identifying the principal components, which are linear combinations of the original features that capture the maximum amount of variance.\nEg.Let's consider a dataset with five features: age, income, education level, number of years of experience, and job satisfaction. We want to use PCA for feature extraction to reduce the dimensionality of the dataset while retaining the most important information.\n\nStandardize the data: We start by standardizing the features to have zero mean and unit variance.\n\nPerform PCA: We apply PCA on the standardized dataset to identify the principal components. Suppose PCA determines that the first three principal components capture the majority of the variance in the data.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To preprocess the data for building a recommendation system for a food delivery service using Min-Max scaling, you would follow these steps:\n\nUnderstand the dataset: Familiarize yourself with the dataset and the specific features it contains. In this case, the dataset includes features like price, rating, and delivery time.\n\nDetermine the range: Identify the range for each feature. For instance, price could range from $0 to $50, rating from 1 to 5, and delivery time in minutes from 10 to 60.\n\nApply Min-Max scaling: Apply the Min-Max scaling technique to bring all the features within a common range, typically between 0 and 1. Follow the formula:\n\nscaled_value = (value - min_value) / (max_value - min_value)\n\nFor example, let's consider the following dataset snippet:\n\nPrice\tRating\tDelivery Time\n\n10\t4\t30\n\n20\t3\t40\n\n30\t5\t20",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To reduce the dimensionality of a dataset containing many features, such as company financial data and market trends, using PCA for stock price prediction, you would follow these steps:\n\nDataset preparation: Gather the dataset that includes the various features related to company financial data and market trends. Ensure the dataset is properly structured, with each row representing a sample (e.g., a specific time period) and each column representing a feature.\n\nData preprocessing: Before applying PCA, it is crucial to preprocess the data. This typically involves handling missing values, normalizing or standardizing the features, and dealing with outliers.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To perform Min-Max scaling on the dataset [1, 5, 10, 15, 20] and transform the values to a range of -1 to 1, we need to calculate the minimum and maximum values of the dataset and apply the scaling formula.\n\nThe minimum value of the dataset is 1, and the maximum value is 20.\n\nAfter performing Min-Max scaling, the transformed dataset with a range of -1 to 1 is:\n\n[-1, -0.58, -0.06, 0.47, 1]",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ans.To perform feature extraction using PCA on a dataset with features [height, weight, age, gender, blood pressure], we need to follow these steps:\n\nPrepare the dataset: Ensure the dataset is properly structured, with each row representing a sample and each column representing a feature.\n\nData preprocessing: Preprocess the data by handling missing values, normalizing or standardizing the features, and dealing with outliers.\n\nStandardize the data: Standardize the features to have zero mean and unit variance. This step is crucial as PCA is sensitive to the scale of the features, and standardization ensures that all features contribute equally to the PCA analysis.\n\nApply PCA: Perform PCA on the standardized dataset. The PCA algorithm calculates the principal components, which are linear combinations of the original features that capture the maximum variance in the data.\n\nAnalyze explained variance: Analyze the explained variance ratio or eigenvalues associated with each principal component. The explained variance ratio represents the proportion of the total variance explained by each component.\n\nNow, to determine how many principal components to retain, we can consider the cumulative explained variance ratio. It indicates the cumulative amount of variance explained as we include more principal components. A commonly used threshold is to retain components that explain a certain percentage of the total variance, such as 90%.",
      "metadata": {}
    }
  ]
}